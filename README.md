# volga_IT_24_ml

# Решения через GPT
Пробовал промптить LLM, чтобы она выписывала адреса из текста. 
Пробовал локальные, пробовал маленькие (до 4B), остановился на API от Mistral. 
https://mistral.ai/
У них есть бесплатный доступ к API, даже к самой большой модели. Но есть ограничение по количеству запросов. 
Лучше всего, на мой взгляд, сработал подход с обработкой в два этапа. С обработкой в один этап она часто путалась. 

0) Создаем список улиц, и списки всех домов для каждой отдельной улицы

1) Выписываем адреса списком

```json
{
  "text": "Луговое с, Пензенская ул, д. 7, 6, 8, 3, 9, 1, 11, 2, 4, 10, 5 Луговое с, Пензенский пер, д. 2, 1, 7, 5, 3, 9, 4 Луговое с, Дорожная ул, д. 5, 1, 7, 3, 0 Луговое с, Молодежная ул, д. 3, 8, 2, 7, 5, 6, 9, 10, 12 Луговое с, Полевая ул, д. 1 Луговое с, Школьная ул, д. 20 Луговое с, Первомайская ул, д. 23, 21, 29",
  "entities": [
    {"entity": "Пензенская ул, д. 7, 6, 8, 3, 9, 1, 11, 2, 4, 10, 5", "types": ["Полный адрес"]},
    {"entity": "Пензенский пер, д. 2, 1, 7, 5, 3, 9, 4", "types": ["Полный адрес"]},
    {"entity": "Дорожная ул, д. 5, 1, 7, 3, 0", "types": ["Полный адрес"]},
    {"entity": "Молодежная ул, д. 3, 8, 2, 7, 5, 6, 9, 10, 12", "types": ["Полный адрес"]},
    {"entity": "Полевая ул, д. 1", "types": ["Полный адрес"]},
    {"entity": "Школьная ул, д. 20", "types": ["Полный адрес"]},
    {"entity": "Первомайская ул, д. 23, 21, 29", "types": ["Полный адрес"]}
  ]
}
```

2) Для каждой улицы выписываем отдельно название улицы, отдельно номера домов:
```json
{
  "street": "Светлый 3-й пер",
  "houses": ["3", "7", "1", "11", "5", "13", "9"]
}
```

3) Ищем название улицы в списке через нечеткий поиск

4) Для каждого дома ищем его наличие в списке домов на этой улице. Если нашли, добавляем его uuid. 

Проблемы:
* Очень долго + дорого
* Модель не всегда понимает, что написано в сообщении. Иногда путается в аббревиатурах. 
* На локальных маленьких моделях почти не работает. Может быть получится решить дообучением. 
* Много ошибок происходит именно на этапе с нечетким поиском. В том месте, где нужно выбирать номера домов. Скорее всего можно исправить, если удалять все лишние пробелы, делать .lower(), и возможно выбирать самый похожий через нечеткий поиск снова. Но я не успеваю это сделать, потому что запустить скрипт с LLM для 3000 текстов получается слишком долго. 

Плюсы:
* Легко реализовывать

Этот подход в папке twostep_llm. 



# Решения через BERT

https://huggingface.co/urchade/gliner_multi-v2.1
Нашел такую модель для задачи Named Entity Recognition. Перед работой она преобразует текст и классы в эмбеддинги, затем сопостовляет их. Из-за этого модель может работать с любыми классами, без дополнительного обучения. 
У этой модели очень хорошая документация. 

Но "из коробки" она не очень работает для этой задачи, нужно дообучать. 

gliner_volga/synthetic_data_generation.ipynb
Я написал скрипт для создания синтетических данных для нее. Там берется краткое содержание случайной статьи на википедии. Это я делал, чтобы улучшить понимание русского языка у мультиязычного варианта модели. 
Дальше я взял несколько примеров из volgait2024-semifinal-task.csv, и попросил LLM разметить их. 

В итоге всеравно не получилось добиться приличных результатов. 

Нашел скрипт в репозитории GLiNER, который инициализирует пустую модель, создал с весами от 
https://huggingface.co/deepvk/deberta-v1-base
Но для ее обучения нужно много данных. В оригинальной статье брали примерно 45 тысяч предложений. 

При инициализации своей модели можно выбрать span level или token level. Я не эксперементировал с этим, и не знаю какой из этих вариантов лучше. 
Еще есть флаг Nested NER. Видимо это позволяет модели присваивать несколько классов слову. Возможно это было бы полезно для нахождения адреса вцелом, и отдельно домов и улиц в этом адресе. 

Этот подход в папке gliner_volga.
* finetune.ipynb - код, который файнтюнит модель GLiNER, используюя json файлы
* gliner.json - данные для обучения
* run_gliner.ipynb - код с запуском модели
* synthetic_data_generation_for_my_data.ipynb - создаем синтетические размеченные данные из тех текстов, которые даны в файле task.
* synthetic_data_generation.ipynb - берем случайные статьи с википедии, размечаем их для обучения GLiNER

# Мои мысли
Мне кажется "правильное" решение должно быть через что-то легкое, возможно основанное на BERT модели. 
Эта модель сможет подсвечивать адреса, а далее полные адреса искать через нечеткий поиск. 
Модель GLiNER будет хорошей отправной точкой. 

---

Если что, вы можете написать мне в тг, https://t.me/ya_ne_ivan 
или на почту anton.epub@gmail.com