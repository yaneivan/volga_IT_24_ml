{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "addr = pd.read_csv(\"../volgait2024-semifinal-addresses.csv\", sep=';')\n",
    "df = pd.read_csv(\"../volgait2024-semifinal-task.csv\", sep=';')\n",
    "streets = list(addr['house_full_address'])\n",
    "\n",
    "\n",
    "street_to_uuid = dict(zip(addr['house_full_address'], addr['house_uuid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in C:\\Users\\admin\\Desktop\\semifinal\\gliner_train\\models\\checkpoint-1500\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ульяновск г, Луначарского ул, д. 3, 11, 5, 9, 7 Ульяновск г, Гая пр-кт, д. 21 Ульяновск г, Соловьева ул, д. 1\n",
      "\n",
      "Гая пр-кт, д. 21 => Полный адрес\n",
      "\t Гая пр-кт -> street name (without house numbers)\n",
      "Соловьева ул, д. 1 => Полный адрес\n",
      "\t Соловьева ул -> street name (without house numbers)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"models/checkpoint-1500\")\n",
    "# base_model = GLiNER.from_pretrained(\"urchade/gliner_multi-v2.1\")\n",
    "\n",
    "for text in df['comment'].sample():\n",
    "    labels = [\"Полный адрес\"]\n",
    "\n",
    "    entities = model.predict_entities(text, labels, threshold=0.1)\n",
    "\n",
    "    print()\n",
    "    print(text)\n",
    "    print()\n",
    "    for entity in entities:\n",
    "        print(entity[\"text\"], \"=>\", entity[\"label\"])\n",
    "        \n",
    "        sublabels = ['street name (without house numbers)']\n",
    "        subentities = base_model.predict_entities(entity['text'], sublabels, threshold=0.3)\n",
    "\n",
    "        for subentitiy in subentities:\n",
    "            print('\\t', subentitiy['text'], '->', subentitiy['label'])\n",
    "\n",
    "        # print(find_street_names_and_numbers(entity['text']))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print('\\n\\n')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Тухачевского/Федерации', 'all')\n",
      "('Ленина', 'all')\n",
      "('Северная', ['3'])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def is_street_name(part):\n",
    "    \"\"\"\n",
    "    Determine if the given part is a street name by checking if it contains more letters than digits\n",
    "    and has a minimum length of 3 characters.\n",
    "\n",
    "    Parameters:\n",
    "    part (str): The part to check.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the part is a street name, False otherwise.\n",
    "    \"\"\"\n",
    "    letters = sum(c.isalpha() for c in part)\n",
    "    digits = sum(c.isdigit() for c in part)\n",
    "    return letters > digits and len(part) >= 3\n",
    "\n",
    "def find_street_names_and_numbers(text):\n",
    "    \"\"\"\n",
    "    Find street names and house numbers in the given text by splitting the text and analyzing each part.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The text to search for street names and house numbers.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the street name and a list of house numbers or 'all'.\n",
    "    \"\"\"\n",
    "    # Split the text into parts using a regular expression to handle multiple delimiters\n",
    "    parts = re.split(r'[ ,]+', text)\n",
    "    street_name = None\n",
    "    house_numbers = []\n",
    "\n",
    "    for part in parts:\n",
    "        if is_street_name(part):\n",
    "            if street_name:\n",
    "                if not house_numbers:\n",
    "                    house_numbers = 'all'\n",
    "                return (street_name, house_numbers)\n",
    "            street_name = part\n",
    "        elif part.isdigit() or re.match(r'\\d+[а-яА-Я]?', part):\n",
    "            house_numbers.append(part)\n",
    "\n",
    "    if not house_numbers:\n",
    "        house_numbers = 'all'\n",
    "\n",
    "    return (street_name, house_numbers)\n",
    "\n",
    "# Example usage:\n",
    "text1 = \"Тухачевского/Федерации утечка из-под земли д=150. без ХВС пер Федерации с 34 по 40.ул Северная с 3 по11. ул Федерации  с 141 по193\"\n",
    "text2 = \"Ленина\"\n",
    "\n",
    "result1 = find_street_names_and_numbers(text1)\n",
    "result2 = find_street_names_and_numbers(text2)\n",
    "\n",
    "print(result1)  # Output: ('Тухачевского/Федерации', 'all')\n",
    "print(result2)  # Output: ('Ленина', 'all')\n",
    "print(find_street_names_and_numbers(\"ул Северная с 3 по11\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
